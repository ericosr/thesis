{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "mcANP9ZjFM2O",
    "outputId": "059306bf-cc94-4f06-f2d6-2987ee8bcad6"
   },
   "outputs": [],
   "source": [
    "#!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "i4a0DmABGEgi",
    "outputId": "72beeefa-a3da-45d9-ee7b-086058c96059"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfwR8RtJGYtD"
   },
   "outputs": [],
   "source": [
    "# !cp '/content/gdrive/My Drive/court_cases.csv.zip' 'court_cases.csv.zip'\n",
    "# !unzip court_cases.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "id": "yzhDMtZCHX_C",
    "outputId": "b627498f-3381-4eed-f439-a3eadd9f43a5"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip court_cases.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZvIlZ2RAFBqH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.ensemble\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import lime\n",
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VZ-odN4FKl-"
   },
   "outputs": [],
   "source": [
    "import html,nltk\n",
    "from nltk.corpus import wordnet \n",
    "from collections import Counter \n",
    "from string import digits\n",
    "\n",
    "def text_cleaning(text, escape_list=[], stop=[]):\n",
    "    \"\"\"\n",
    "    Text cleaning function:\n",
    "    \"\"\"\n",
    "    text=text.lower()\n",
    "    StopWords = list(set(stopwords.words('dutch')))\n",
    "    custom_stop = StopWords + stop\n",
    "    text = html.unescape(text)\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    text=text.replace('/',' ').replace('?',' ').replace(',',' ').replace('\\'',' ')\n",
    "    tokenz=nltk.word_tokenize(text)\n",
    "    tokenz=([token for token in tokenz if token not in custom_stop]) \n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    return ' '.join(tokenz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVPAKbqbFd78"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"court_cases.csv\", lineterminator='\\n', index_col=0)\n",
    "df['Full Text'] = df['process'] + ' ' + df['considerations']\n",
    "df['Full Text'] = df['Full Text'].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTGM9DkuFghO"
   },
   "outputs": [],
   "source": [
    "def do_cross_validation(models,features,labels,CV=5):\n",
    "    cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "    entries = []\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV,n_jobs=-1)\n",
    "        for fold_idx, accuracy in enumerate(accuracies):\n",
    "            entries.append((model_name, fold_idx, accuracy))\n",
    "    cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "    plot_cv_result(cv_df)\n",
    "    return cv_df\n",
    "\n",
    "def plot_cv_result(cv_df):\n",
    "    sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "    sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "                  size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_prediction(model,X_train,y_train,X_test,y_test):\n",
    "    y_pred_trn = model.predict(X_train)\n",
    "    conf_mat = confusion_matrix(y_train, y_pred_trn)\n",
    "    print(f'Accuracy for Training Set is  : {accuracy_score(y_train, y_pred_trn)}')\n",
    "    print(f'Confusion Matrix for Training Set :\\n {conf_mat} \\n\\n Classification Report for Training Set: \\n')\n",
    "    print(classification_report(y_train, y_pred_trn))\n",
    "    print('--'*50)\n",
    "    y_pred_tst = model.predict(X_test)\n",
    "    conf_mat_tst = confusion_matrix(y_test, y_pred_tst)\n",
    "    print(f'Accuracy for Testing Set is  : {accuracy_score(y_test, y_pred_tst)}')\n",
    "    print(f'Confusion Matrix for Testing Set :\\n {conf_mat_tst} \\n\\n Classification Report for Testing Set: /n')\n",
    "    print(classification_report(y_test, y_pred_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RVV4DGiQsGg"
   },
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "Mx0Zwe5DFiIH",
    "outputId": "60a6c7c4-201c-4eb7-f4cf-366f58fca9eb"
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(16,6)})\n",
    "countvec = CountVectorizer(min_df=5,ngram_range=(1,2))\n",
    "features = countvec.fit_transform(df['Full Text'])\n",
    "labels = df.outcome\n",
    "print(features.shape)\n",
    "\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "cv_df_countvec = do_cross_validation(models,features,labels,CV=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "9cGicapuQm8j",
    "outputId": "e4bdc46b-83e8-4ebc-8155-8c49a8aa4a5d"
   },
   "outputs": [],
   "source": [
    "cv_df_countvec.groupby('model_name')['accuracy'].mean().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R80IdZmSQy56"
   },
   "source": [
    "##### TF-IDF Vectorizer Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "E7kaTSNOFkw-",
    "outputId": "260216b0-6ea8-49dd-b955-8fd1101f38af"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2',ngram_range=(1,2))\n",
    "features = tfidf.fit_transform(df['Full Text'])\n",
    "labels = df.outcome\n",
    "print(features.shape)\n",
    "\n",
    "\n",
    "cv_df_tfidf = do_cross_validation(models,features,labels,CV=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "z4kc5Z5ixDtC",
    "outputId": "472ed0a8-fc67-409f-9273-5fe66b1414dc"
   },
   "outputs": [],
   "source": [
    "cv_df_tfidf.groupby('model_name')['accuracy'].mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3CUOOk5Sjz9"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Full Text'], df.outcome, test_size=0.3, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "t0EqcDbsvKZE",
    "outputId": "5f830401-a93f-4397-f9c4-df860d3cff4d"
   },
   "outputs": [],
   "source": [
    "#TFIDF with SVC had best performance\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2',ngram_range=(1,2))\n",
    "pipeline = make_pipeline(tfidf,CalibratedClassifierCV(LinearSVC(),method='isotonic'))\n",
    "pipeline.fit(X_train,y_train)\n",
    "get_prediction(pipeline,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KksdxTmvXux5"
   },
   "outputs": [],
   "source": [
    "def plot_features_of_explained_model(exp,selected_label):\n",
    "    imp = pd.DataFrame(exp.as_list(label=selected_label))\n",
    "    imp.set_index(0,inplace=True)\n",
    "    imp['color'] = imp[1].apply(lambda x:'Positive' if x>=0 else 'Negative')\n",
    "    imp[1] = imp[1].apply(abs)\n",
    "\n",
    "    sns.set(rc={'figure.figsize':(12,12)})\n",
    "    palette = [\"#55a868\",\"#c44e52\"]\n",
    "    ax = sns.barplot(x=imp[1], y=imp.index,hue=imp['color'],palette=palette, dodge=False,hue_order=[\"Positive\", \"Negative\"]).set_title(f'Feature Importance for Label {selected_label}',fontsize=15)\n",
    "    plt.show()\n",
    "    print('Importance of words directly in the text : \\n')\n",
    "    exp.show_in_notebook(text=True,labels=[selected_label])\n",
    "\n",
    "def explain_model(pipeline,X,y,idx,num_features):\n",
    "    class_names=list(y.unique())\n",
    "    explainer = LimeTextExplainer(class_names=class_names)\n",
    "    exp = explainer.explain_instance(X[idx], pipeline.predict_proba, num_features=num_features, labels=[0,1])\n",
    "    print('Document id: %d' % idx)\n",
    "    predicted_class = class_names[pipeline.predict(X[idx:idx+1]).reshape(1,-1)[0,0]]\n",
    "    class_proba = pipeline.predict_proba(X[idx:idx+1]).max()\n",
    "    print(f'Predicted class = {predicted_class} ({round(class_proba,4)*100}%)')\n",
    "    print('Real class: %s' % class_names[y[idx]])\n",
    "    print(f\"Prediction is {'Correct' if (class_names[y[idx]]==class_names[pipeline.predict(X[idx:idx+1]).reshape(1,-1)[0,0]]) else 'Wrong'}.\")\n",
    "    plot_features_of_explained_model(exp=exp,selected_label=y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CsSYy_LSYpMn",
    "outputId": "6af019d4-6a9b-48a3-e399-2d55843d4de6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#See feature importance for specific model\n",
    "DOCUMENT_INDEX = 190\n",
    "explain_model(pipeline=pipeline,X=df['Full Text'],y=df.outcome,idx=DOCUMENT_INDEX,num_features=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "m7UtgosdulIW",
    "outputId": "d26d9099-3fb0-40e4-96d5-c0a714e42b8d"
   },
   "outputs": [],
   "source": [
    "X,y = df['Full Text'],df.outcome\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2',ngram_range=(1,2))\n",
    "pipeline = make_pipeline(tfidf,CalibratedClassifierCV(LinearSVC(),method='isotonic'))\n",
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWXVmTRi39tU"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6nV3a5W12vo"
   },
   "outputs": [],
   "source": [
    "def get_feature_importance_for_full_document(X,y,num_features = 500):\n",
    "    '''\n",
    "    Returns Importance as Class 0 Importance\n",
    "    '''\n",
    "    class_names=[0, 1]\n",
    "    explainer = LimeTextExplainer(class_names=class_names)\n",
    "    full_df = pd.DataFrame()\n",
    "    for idx in tqdm(range(len(X))):\n",
    "        exp = explainer.explain_instance(X[idx], pipeline.predict_proba, num_features=num_features, labels=[0,1])\n",
    "        imp = pd.DataFrame(exp.as_list(label=0),columns=['word','importance'])\n",
    "        imp['ID'] = idx\n",
    "        imp['Real Class'] = y[idx]\n",
    "        imp['Predicted Class'] = pipeline.predict(X[idx:idx+1]).reshape(1,-1)[0,0]\n",
    "        imp['Predicted Class Probability'] = pipeline.predict_proba(X[idx:idx+1]).max()\n",
    "        full_df = pd.concat([full_df,imp])\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "id": "l8ePUZbp5OYf",
    "outputId": "ef6d696e-d82e-4dc9-ce16-18f61399eafd"
   },
   "outputs": [],
   "source": [
    "single_processing_op = get_feature_importance_for_full_document(X[:20],y[:20],num_features = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3zRmaci8E2O"
   },
   "outputs": [],
   "source": [
    "def get_feature_importance_for_full_document_parallel(X,y,idx,num_features):\n",
    "    '''\n",
    "    Returns Importance as Class 0 Importance\n",
    "    '''\n",
    "#     print(f'Starting : {idx} {time.time()}')\n",
    "\n",
    "    explainer = LimeTextExplainer(class_names=[0,1])\n",
    "    exp = explainer.explain_instance(X, pipeline.predict_proba, num_features=num_features, labels=[0,1])\n",
    "    imp = pd.DataFrame(exp.as_list(label=0),columns=['word','importance'])\n",
    "    imp['ID'] = idx\n",
    "    imp['Real Class'] = y\n",
    "    imp['Predicted Class'] = pipeline.predict([X]).reshape(1,-1)[0,0]\n",
    "    imp['Predicted Class Probability'] = pipeline.predict_proba([X]).max()\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nowUnIC9BemJ",
    "outputId": "135d050d-d84c-4a4b-c3ff-c78f20f4555e"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with multiprocessing.Pool(processes=100) as pool:\n",
    "    results = pool.starmap(get_feature_importance_for_full_document_parallel, [(X[idx],y[idx],idx,500) for idx in range(len(X))])\n",
    "full_df = pd.concat(results)\n",
    "end = time.time()\n",
    "\n",
    "total_time = end - start\n",
    "# print('Time :',total_time)\n",
    "print(f'With multiprocessing the job was finished in {int(total_time/3600)} hours {int(round(((total_time/3600)%1)*60,0))} minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_from_full_data(imp,top_n = 50,label=0):\n",
    "#     imp = pd.DataFrame(exp.as_list(label=selected_label))\n",
    "#     imp.set_index('word',inplace=True)\n",
    "    imp['color'] = imp['importance'].apply(lambda x:'Positive' if x>=0 else 'Negative')\n",
    "    imp['importance'] = imp['importance'].apply(abs)\n",
    "    imp = imp.sort_values('importance',ascending=False)[:top_n]\n",
    "    sns.set(rc={'figure.figsize':(12,12)})\n",
    "    palette = [\"#55a868\",\"#c44e52\"]\n",
    "    ax = sns.barplot(x=imp['importance'], y=imp.index,hue=imp['color'],palette=palette, dodge=False,hue_order=[\"Positive\", \"Negative\"]).set_title(f'Feature Importance for Entire Data (Class {label})',fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_features = full_df[(full_df['Real Class']==full_df['Predicted Class']) & (full_df['Real Class']==0)].groupby('word')['importance'].mean().to_frame()\n",
    "plot_features_from_full_data(class_0_features,top_n=50,label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1_features = full_df[(full_df['Real Class']==full_df['Predicted Class']) & (full_df['Real Class']==1)].groupby('word')['importance'].mean().to_frame()\n",
    "class_1_features['importance'] = class_1_features['importance']*-1\n",
    "plot_features_from_full_data(class_1_features,top_n=50,label=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Court Cases - Model Evaluation, Validation and Explainability.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
