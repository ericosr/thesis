{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import xmltodict\n",
    "import time\n",
    "import pickle\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "import random \n",
    "from ipynb.fs.full.Preprocessing_Methods import get_detailed_sentence\n",
    "from ipynb.fs.full.Preprocessing_Methods import get_html_from_detailed_link\n",
    "from ipynb.fs.full.Preprocessing_Methods import get_ecli_from_detailed_link\n",
    "from ipynb.fs.full.Preprocessing_Methods import find_index\n",
    "from ipynb.fs.full.Preprocessing_Methods import get_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Structured Cases are those that have html tags defining the subsections\n",
    "structured == 0.0, indicates that the case is unstructred, and structured == 1.0\n",
    "indicates that the case is structured\"\"\"\n",
    "\n",
    "cases_df = pd.read_csv(\"asylum_cases_structure.csv\", index_col=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_cases = cases_df[cases_df.structured == 1.0]\n",
    "ECLI_structured_cases = structured_cases['case'].tolist()\n",
    "unstructured_cases = cases_df[cases_df.structured == 0.0]\n",
    "ECLI_unstructured_cases = unstructured_cases['case'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subsections(ECLI_list, unstructured = True):\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    discard = []\n",
    "\n",
    "\n",
    "    regex_procesverloop = \"\\r\\n[ ]{0,}([0-9]*)?(\\.)?([0-9]*)?([i|v|x]*)?[ ]{0,}(de)?(het)?[ ]{0,}(\\.)?[ ]{0,}(procesverloop|ontstaan en loop van het geding|zitting|gegevens inzake het geding|verloop van de procedure|ontstaan en loop van het geschil|inleiding|ontstaan en loop van de gedingen)(en)?(:)?[ ]{0,}(\\.)?[ ]{0,}\\r\\n\"\n",
    "\n",
    "\n",
    "    \n",
    "    regex_beslissing = \"\\r\\n[ ]{0,}([0-9]*)?(\\.)?([0-9]*)?([i|v|x]*)?[ ]{0,}(de)?(het)?[ ]{0,}(\\.)?[ ]{0,}(beslissing|uitspraak)(en)?(:)?[ ]{0,}(\\.)?[ ]{0,}\\r\\n\"\n",
    "            \n",
    "    \n",
    "    regex_overwegingen = \"\\r\\n[ ]{0,}([0-9]*)?(\\.)?([0-9]*)?([i|v|x]*)?[ ]{0,}(de)?(het)?[ ]{0,}(\\.)?[ ]{0,}(rechtsoverwegingen|overwegingen|motivering|gronden|beoordeling|feiten)(en)?(:)?[ ]{0,}(\\.)?[ ]{0,}\\r\\n\"\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    DETAILED_LINK_URL = \"https://data.rechtspraak.nl/uitspraken/content?id={}\"\n",
    "    \n",
    "    detailed_link_list = [ecli for ecli in ECLI_list]\n",
    "    \n",
    "    text_df = pd.DataFrame({\"case\": [],\n",
    "                            \"procesverloop\": [],\n",
    "                            \"overwegingen\": [],\n",
    "                            \"beslissing\": []\n",
    "                           })\n",
    "    \n",
    "    \n",
    "    for detailed_link in detailed_link_list:\n",
    "        \n",
    "        counter +=1\n",
    "        print(counter, end=\"\\r\", flush=True)\n",
    "        time.sleep(0.001)\n",
    "        ecli_temp = get_ecli_from_detailed_link(detailed_link)\n",
    "        \n",
    "        detailed_sentence = get_detailed_sentence(ecli_temp)\n",
    "        \n",
    "        if unstructured:\n",
    "            text = get_html_from_detailed_link(detailed_sentence)\n",
    "            full_text = text.getchildren()[-1]\n",
    "            content = full_text.text_content()\n",
    "            content = content.lower()\n",
    "            content = content.strip()\n",
    "            content = content.replace('\\xa0', '')\n",
    "            content = content.replace('\\t', '')\n",
    "            x = re.search(regex_beslissing, content)\n",
    "            \n",
    "            \n",
    "            if x!= None:\n",
    "                index_procesverloop = find_index(regex_procesverloop,content,False)\n",
    "                index_beslissing = find_index(regex_beslissing,content)\n",
    "                index_overwegingen = find_index(regex_overwegingen, content, False)\n",
    "                \n",
    "                if index_beslissing == \"no_index_found\":\n",
    "                    discard.append(detailed_link)\n",
    "                    continue\n",
    "\n",
    "\n",
    "                else:\n",
    "                    beslissing = content[index_beslissing[0]:]\n",
    "                    beslissing = beslissing.replace(\"\\r\\n\", \"\")\n",
    "                \n",
    "                if index_overwegingen == \"no_index_found\":\n",
    "                    discard.append(detailed_link)\n",
    "                    continue\n",
    "\n",
    "\n",
    "                else:\n",
    "                    overwegingen = content[index_overwegingen[0]:index_beslissing[1]]\n",
    "                    overwegingen = overwegingen.replace(\"\\r\\n\", \"\")\n",
    "                    \n",
    "                if index_procesverloop == \"no_index_found\":\n",
    "                    discard.append(detailed_link)\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    procesverloop = content[index_procesverloop[0]:index_overwegingen[1]]\n",
    "                    procesverloop = procesverloop.replace(\"\\r\\n\", \"\")\n",
    "\n",
    "\n",
    "                \n",
    "                df_temp = pd.DataFrame({\n",
    "                \"case\": [ecli_temp],\n",
    "                \"procesverloop\" : [procesverloop],\n",
    "                \"overwegingen\" : [overwegingen],\n",
    "                \"beslissing\" : [beslissing]\n",
    "                })\n",
    "                \n",
    "                text_df = text_df.append(df_temp, ignore_index=True)\n",
    "        else:\n",
    "            \n",
    "            soup = BeautifulSoup(detailed_sentence.content, 'html.parser')\n",
    "            \n",
    "            string_beslissing = ['<section role=\"beslissing\">', '<emphasis role=\"bold\">beslissing', \n",
    "                                 \"<title>beslissing\", '<bridgehead role=\"bold\">beslissing', '<para>beslissing'\n",
    "                                ]\n",
    "            string_overwegingen = ['<section role=\"overwegingen\">', '<emphasis role=\"bold\">overwegingen',\n",
    "                                   \"<title>overwegingen\", '<?linebreak?>overwegingen',\n",
    "                                   '<title>de beoordeling',\n",
    "                                  '<emphasis role=\"bold\">overwegingen', '<title>Motivering']\n",
    "            \n",
    "            string_procesverloop = ['<section role=\"procesverloop\">', '<title>zitting', '<title>procesverloop']  \n",
    "\n",
    "            \n",
    "       \n",
    "            element_list = [x for x in [str(child).lower() for child in soup.findAll('section')]]\n",
    "            \n",
    "            \n",
    "            index_beslissing = get_index(string_beslissing, element_list)\n",
    "            index_overwegingen = get_index(string_overwegingen, element_list )\n",
    "            index_procesverloop = get_index(string_procesverloop,  element_list )\n",
    "            \n",
    "\n",
    "\n",
    "            if index_beslissing == \"no_index_found\":\n",
    "                discard.append(detailed_link)\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                content_beslissing = soup.find_all(\"section\")[index_beslissing].get_text()\n",
    "                content_beslissing = content_beslissing.lower()\n",
    "                content_beslissing = content_beslissing.replace(\"\\n\", \"\")\n",
    "                content_beslissing = content_beslissing.replace(\"\\t\", \"\")\n",
    "                content_beslissing = content_beslissing.replace(\"beslissing\", \"\", 1)\n",
    "                content_beslissing = content_beslissing.lower()\n",
    "                \n",
    "            \n",
    "            if index_overwegingen == \"no_index_found\":\n",
    "                discard.append(detailed_link)\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                content_overwegingen  = soup.find_all(\"section\")[index_overwegingen].get_text()\n",
    "                content_overwegingen = content_overwegingen.lower()\n",
    "                content_overwegingen = content_overwegingen.replace(\"\\n\", \"\")\n",
    "                content_overwegingen = content_overwegingen.replace(\"\\t\", \"\")\n",
    "                content_overwegingen = content_overwegingen.replace(\"overwegingen\", \"\", 1)\n",
    "                content_overwegingen = content_overwegingen.lower()\n",
    "\n",
    "            \n",
    "                \n",
    "            if index_procesverloop == \"no_index_found\":\n",
    "                discard.append(detailed_link)\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                content_procesverloop = soup.find_all(\"section\")[index_procesverloop].get_text()\n",
    "                content_procesverloop = content_procesverloop.lower()\n",
    "                content_procesverloop = content_procesverloop.replace(\"\\n\", \"\")\n",
    "                content_procesverloop  = content_procesverloop.replace(\"\\t\", \"\")\n",
    "                content_procesverloop  = content_procesverloop.replace(\"procesverloop\", \"\", 1)\n",
    "                content_procesverloop  = content_procesverloop.lower()\n",
    "\n",
    "             \n",
    "                \n",
    "            df_temp = pd.DataFrame({\n",
    "                \"case\": [ecli_temp],\n",
    "                \"procesverloop\" : [content_procesverloop],\n",
    "                \"overwegingen\" : [content_overwegingen],\n",
    "                \"beslissing\" : [content_beslissing]\n",
    "            })\n",
    "                \n",
    "            text_df = text_df.append(df_temp, ignore_index=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    return text_df, discard\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsections = generate_subsections(ECLI_unstructured_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsections[0].to_csv(\"unstructured_with_subsections.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"unstructured_list.txt\", \"wb\") as fp:\n",
    "        pickle.dump(subsections[1], fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
